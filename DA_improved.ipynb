{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2PefRgXmxvmAsXUDYqQEp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EP111111/Doc_analysis/blob/main/DA_improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AxvuhS37JxXy"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shapely==1.8.5\n"
      ],
      "metadata": {
        "id": "z4a_dGAVMGmq",
        "outputId": "752fd7bd-6655-4b39-d216-3e964c9328ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shapely==1.8.5 in /usr/local/lib/python3.10/dist-packages (1.8.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install google-cloud-aiplatform --upgrade\n",
        "!pip install python-docx\n",
        "!pip install langchain\n",
        "!pip install docx2txt\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "PwLoIy3uKEzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "from google.colab import drive\n",
        "import docx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functions import *"
      ],
      "metadata": {
        "id": "nkzNFWZ_Ke0F"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "5bMKMXHa6zkD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"ics-analysis-dev\"\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
        "\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n"
      ],
      "metadata": {
        "id": "gKNNxk4bK4C3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Document Splitting\n",
        "Document Splitting is to split documents into smaller chunks."
      ],
      "metadata": {
        "id": "ervrvRLG62fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import Docx2txtLoader\n",
        "text=Docx2txtLoader(\"Project Alpha.docx\").load()"
      ],
      "metadata": {
        "id": "GTSlrm5wR1C0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=150,\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(text)\n"
      ],
      "metadata": {
        "id": "HbRK-HN4SSrg"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector Stores and Embeddings\n",
        " put these chunks into an index so that we are able to retrieve them easily when we want to answer questions on this document."
      ],
      "metadata": {
        "id": "rS1xO11o7KN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = VertexAIEmbeddings()\n",
        "# Create the vector store\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"/content\"\n",
        ")\n",
        "\n",
        "print(vectordb._collection.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DglX-oCKVYGX",
        "outputId": "90dbde23-3a71-499a-8935-4a5885d533a4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatVertexAI\n",
        "llm = ChatVertexAI()"
      ],
      "metadata": {
        "id": "LdgdQPoTnDTm"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordb.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "oyhG2iYeo6fE"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"extract all questions in this document  :\n",
        "\"\"\"\n",
        "result = qa_chain({\"query\": question})\n",
        "print(result[\"result\"])\n",
        "\n",
        "import re\n",
        "\n",
        "questions = re.split(r'\\d+\\.', result[\"result\"])\n",
        "questions = [q.strip() for q in questions if q.strip()]\n",
        "\n",
        "# for i, question in enumerate(questions, start=1):\n",
        "#     print(f\"{i}. {question}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH7ZRVfzpMZp",
        "outputId": "49f3fcef-3f31-4d27-b7c9-5942ea5a94bc"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1. What is the purpose of this RFP? \n",
            "2. What is the background of the service? \n",
            "3. What are the general information about Project Alpha? \n",
            "4. What are the terms and conditions of the project? \n",
            "5. What are the high-level project requirements? \n",
            "6. What vendor information is required? \n",
            "7. What is the vendor proposal? \n",
            "8. What is the method of evaluations and award? \n",
            "9. What are the attachments? \n",
            "10. What is the timesheet allocation worksheet? \n",
            "11. What is the activity based\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(docs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDxu3S1dxwhK",
        "outputId": "78cdf222-cac5-45f9-ff08-e99d73006a25"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find the context to the questions in each different part\n",
        "\n",
        "EXTRACT context related to the question"
      ],
      "metadata": {
        "id": "R2kdoNHf4WC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def take_context(question,cont):\n",
        "#   ques=f'''\n",
        "#   Document:{cont}\n",
        "#   ___above this line is the document,below this line is what you need to do___\n",
        "#   EXTRACT context related to the   question:[\"{question}\"]. The output must be analysed from the above Document,\n",
        "\n",
        "#   if no context related to the input exist, return:\"no\" only\n",
        "\n",
        "#   question:[\"{question}\"]\n",
        "\n",
        "#   output:context OR \"No\"\n",
        "#   '''\n",
        "\n",
        "#   result = qa_chain({\"query\": question})\n",
        "\n",
        "\n",
        "#   return result[\"result\"]\n",
        "\n",
        "def take_context(question,cont,model):\n",
        "    context=empty_Vertex(f'''\n",
        "    Document:{cont}\n",
        "    ___above this line is the document,below this line is what you need to do___\n",
        "    EXTRACT context related to the question. The output must be from the above Document, if no context related to the input exist, return:\"no\" only\n",
        "\n",
        "    question:[\"{question}\"]\n",
        "    output:context OR \"no\"\n",
        "    ''',model)\n",
        "    return context\n"
      ],
      "metadata": {
        "id": "MlTS0klvwjvH"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def docs_context(ques,docs):\n",
        "  print(\"question: \" + ques +\"\\n\\nThere are \"+str(len(docs))+ \" sections\\n\")\n",
        "\n",
        "\n",
        "  for i in range(len(docs)):\n",
        "    res= take_context(ques,docs[i].page_content,model)\n",
        "    print(\"\\nsection \"+str(i)+\":\\ncontext related to the question :\"+ res)\n",
        "    print(\"##################\")\n",
        "docs_context(questions[4],docs)"
      ],
      "metadata": {
        "id": "T5Zy3Xlu57YH",
        "outputId": "4b6e41a2-8932-49ed-8847-d281202b432f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What are the high-level project requirements?\n",
            "\n",
            "There are 22 sections\n",
            "\n",
            "\n",
            "section 0:\n",
            "context related to the question :The high-level project requirements are as follows:\n",
            "\n",
            "- Standards and Conventions\n",
            "- Project Management\n",
            "- Engagement Governance\n",
            "- Technical & Data Conversion Requirements\n",
            "- Testing\n",
            "##################\n",
            "\n",
            "section 1:\n",
            "context related to the question :This RFP document is an invitation to submit proposals for a project to replace an existing legacy software system, while providing much needed enhancements to the overall business processes. This project will be established as Project Alpha and the start date is slated for January. Timeline to implementation and cut over will be a determining factor in our evaluations.\n",
            "##################\n",
            "\n",
            "section 2:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 3:\n",
            "context related to the question :We are seeking a product that will not only replace the system we have but enhance our user experience and allow us to grow and expand as new areas arise where we can provide our services through new programs. The new system will need to accommodate our 150+ user base as well as provide a pathway to share our data with partners through API interactions or other easily used mechanisms. Most, if not all, programs will contain Personally Identifiable Information, therefore data storage and exchange will need to conform to security standards for PII, such as the California Consumer Protection Act (CCPA). Along with this, we do have programs which store medical record data. Any new system we evaluate will have to comply with HIPAA standards for those specific programs, if not across the entire system.\n",
            "##################\n",
            "\n",
            "section 4:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 5:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 6:\n",
            "context related to the question :Ability to have total labor costs in projects\n",
            "\tLabor cost breakdown by type\n",
            "\tWeatherization\n",
            "\tHealth/Safety\n",
            "\tRepair\n",
            "\tCRM\n",
            "\t\n",
            "\tCustom User Form Creation / Data Entry Management\n",
            "\tSimilar to a Google Form for collecting data\n",
            "\tSurvey Creation and Management\n",
            "\tScheduling and Calendar\n",
            "\tLocal and Web based\n",
            "\tReminder Call System\n",
            "\tPhone / Text\n",
            "\tCustomizable Data Entry Fields\n",
            "\tUnlimited in number\n",
            "\tMust be able to perform calculations to populate other fields (including custom)\n",
            "\tMust be able to report on these fields\n",
            "\tCustomizable Calculation Fields\n",
            "\tUnlimited in number\n",
            "\tMust be able to populate other fields\n",
            "\tMust be able to report on these fields\n",
            "\tCustomizable Reporting\n",
            "\tSpecific Report Generation\n",
            "\tFor reports more complex than can be built in the Customizable Reporting Solution\n",
            "\tEach program will need up to 15 reports created by the installation team during the transition process for use upon go-live\n",
            "\tData Integration with Third-Party Systems\n",
            "\tEach program will have specific needs for use of Application Programming Interfaces between the new system and the third- party systems.\n",
            "\tThe new system should allow for both data export and import using these Application Programming Interfaces\n",
            "\tData Security\n",
            "\tHIPAA Compliance – There are certain programs which store data which needs to be HIPAA compliant. As such, the new system will have to be compliant with the HIPAA standard for at ‘minimum’ those programs\n",
            "\tPersonally Identifiable Information – All client data stored within the system contains Personally Identifiable information, in most cases the Social Security Number is stored.\n",
            "\tAccounting\n",
            "The accounting team works with the Blackbaud Financial Edge package to manage the day-to-day accounting needs. This system has worked well in the past, but they are open to investigating new solutions if that is in the best interest of the overall software suite, however if possible it would be preferred for there to be integration between the new Community Action system and Financial Edge.\n",
            "\tAR\n",
            "##################\n",
            "\n",
            "section 7:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 8:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 9:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 10:\n",
            "context related to the question :Standards and Conventions\n",
            "All software code written will comply with industry standards for code quality, documentation and quality assurance testing based on the software programming language used for implementation and to be agreed upon during contract negotiations.\n",
            "\tProject Management\n",
            "The project will be managed by the Project Management Team at AGENTS with the following requirements:\n",
            "\tThere will be 15-30-minute Project Management Status Check in meetings on the following days:\n",
            "\tMonday – Plan for the week\n",
            "\tTuesday – Roadblock Check in\n",
            "\tWednesday – Check in on current weekly goals / roadblocks\n",
            "\tThursday – Roadblock Check in\n",
            "\tFriday – Summarize week achievements / roadblocks\n",
            "\tWeekly Reports on Progress and Roadblocks required\n",
            "\tMonthly Reports on Progress and Roadblocks required Format to be determined, however must include Scope, Schedule and Budget color coded to Red, Yellow and Green for status\n",
            "\tChange Request Management Meetings for formal review and approval of anything outside the initial scope of the project as needed\n",
            "\tShould roadblocks or other needs arise, meetings to address the given situation will be set up\n",
            "\tDemonstrations will be given upon completion of software customizations\n",
            "\tEngagement Governance\n",
            "\t\tThe Vendor must present a formal report on progress and accomplishments every week and month\n",
            "\t\tThe monthly progress report shall include, at a minimum, the following information:\n",
            "##################\n",
            "\n",
            "section 11:\n",
            "context related to the question :The monthly progress report shall include, at a minimum, the following information:\n",
            "\tProject schedule fidelity\n",
            "\tProject progress\n",
            "\tMajor accomplishments of the past week/month\n",
            "\tSummary of risks and mitigation activities\n",
            "\tSummary of issues and impacts\n",
            "##################\n",
            "\n",
            "section 12:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 13:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 14:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 15:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 16:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 17:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 18:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 19:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 20:\n",
            "context related to the question :no\n",
            "##################\n",
            "\n",
            "section 21:\n",
            "context related to the question :no\n",
            "##################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res= take_context(questions[0],docs[0].page_content,model)\n",
        "print(res)\n",
        "\n",
        "res= take_context(questions[0],docs[1].page_content,model)\n",
        "print(res)\n",
        "\n",
        "res= take_context(questions[0],docs[2].page_content,model)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "rh1j5rTy7s5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}